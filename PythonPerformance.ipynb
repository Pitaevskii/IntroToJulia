{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29a2b0b0",
   "metadata": {},
   "source": [
    "# Julia vs. Python\n",
    "\n",
    "**Julia Workshop: Compute the future** (23/11/2023)<br>\n",
    "Presenter: Robbe Ceulemans\n",
    "\n",
    "## Estimating $\\pi$ \\[1\\]\n",
    "You have just started learning the basics of Julia, because some random person is convinced it is as easy to learn as **Python** but with better performance. Is it really? Let's put it to the test. In this notebook a simple example of estimating the value of $\\pi$ using Monte Carlo sampling is used to compare [\\[1\\]](https://blakeaw.github.io/2019-09-20-numba-vs-julia/). In a first instance a naive Python implementation is tested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d69eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ebfd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_pi(nMC):\n",
    "    radius = 1.\n",
    "    diameter = 2.*radius\n",
    "    n_circle = 0\n",
    "    for i in range(nMC):\n",
    "        x = (np.random.random()-0.5)*diameter\n",
    "        y = (np.random.random()-0.5)*diameter\n",
    "        r = np.sqrt(x**2 + y**2)\n",
    "        if r <= radius:\n",
    "           n_circle += 1\n",
    "    return 4.*n_circle/nMC\n",
    "\n",
    "nMC = 100000000\n",
    "for i in range(3):\n",
    "    %time pi_est = estimate_pi(nMC)\n",
    "    print(pi_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21e309d",
   "metadata": {},
   "source": [
    "Not the best result, but we shouldn't discredit Python too much, because this can be optimized much more. The `numpy` library can be used to a greater extent besides the random number generating done in this example.<br>\n",
    "<br>\n",
    "In the next example the `for`-loop, that has a notoriously bad performance in Python, is traded for a vectorized solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199a5511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_pi(nMC):\n",
    "    radius = 1.\n",
    "    diameter = 2.*radius\n",
    "    xy = (np.random.random((nMC,2))-0.5) * diameter\n",
    "    r = np.sqrt((xy**2).sum(axis=1))\n",
    "    circle_mask = r <= radius\n",
    "    n_circle = r[circle_mask].shape[0]\n",
    "    print(n_circle)\n",
    "    return 4.*n_circle/nMC\n",
    "\n",
    "nMC = 100000000\n",
    "for i in range(3):\n",
    "    %time pi_est = estimate_pi(nMC)\n",
    "    print(pi_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ed8744",
   "metadata": {},
   "source": [
    "Clearly a great improvement compared to the naive implementation. We gain almost a factor 60 in speed. It does require rewriting (vectorizing) the code, which is possible in this case, but certainly not all the time.<br>\n",
    "<br>\n",
    "An argument that is often brought up as to why Julia is redundant is that there are extensions to Python that also make use of the JIT-compilation. Simply adding one line of code to the naive implementation in Python gives a remarkable speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f59e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "\n",
    "@numba.njit\n",
    "def estimate_pi(nMC):\n",
    "    radius = 1.\n",
    "    diameter = 2.*radius\n",
    "    n_circle = 0\n",
    "    for i in range(nMC):\n",
    "        x = (np.random.random()-0.5)*diameter\n",
    "        y = (np.random.random()-0.5)*diameter\n",
    "        r = np.sqrt(x**2 + y**2)\n",
    "        if r <= radius:\n",
    "           n_circle += 1\n",
    "    return 4.*n_circle/nMC\n",
    "\n",
    "nMC = 100000000\n",
    "for i in range(3):\n",
    "    %time pi_est = estimate_pi(nMC)\n",
    "    print(pi_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac2c523",
   "metadata": {},
   "source": [
    "It's a staggering 180 times faster. So why the need for Julia when packages like Cython and Numba exist? Well, these packages are not guaranteed to speedup all Python functions. There application is limited. Python code was never designed to be compiled.<br>\n",
    "<br>\n",
    "What about Julia's performance for this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b352e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "function estimate_pi(nMC)\n",
    "    radius = 1.\n",
    "    diameter = 2. * radius\n",
    "    n_circle = 0\n",
    "    for i in 1:nMC\n",
    "        x = (rand() - 0.5) * diameter\n",
    "        y = (rand() - 0.5) * diameter\n",
    "        r = sqrt(x^2 + y^2)\n",
    "        if r <= radius\n",
    "           n_circle += 1\n",
    "        end\n",
    "    end\n",
    "    return (n_circle/nMC) * 4.\n",
    "end\n",
    "\n",
    "nMC = 100000000\n",
    "@benchmark pi_est = estimate_pi(nMC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9702328",
   "metadata": {},
   "source": [
    "Even with the most basic implementation of the problem we still gain a factor of almost 3 in performance. Although the gap in performance is not huge, it is clear that this top-speed comes standard with Julia and is not restricted to a subset of functionalities. The solution that Julia offers is full language. It's designed with speed and performance in mind, while at the same time keeping the implementation as simple as possible.<br>\n",
    "<br>\n",
    "For those who are interested in exploring this further, [*the benchmarks game*](https://benchmarksgame-team.pages.debian.net/benchmarksgame/index.html) compares many different toy programs for a whole list of scripting and compiled languages, including Julia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c11262f",
   "metadata": {},
   "source": [
    "\\[1\\] Blake A. Wilson, *Python+Numba vs. Julia; Monte Carlo estimation of Pi*,https://blakeaw.github.io/2019-09-20-numba-vs-julia/, \\[September 2019\\]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cf9796",
   "metadata": {},
   "source": [
    "## Lorenz attractor \\[2\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab8b8a7",
   "metadata": {},
   "source": [
    "Of course you will find benchmarks of small functions (or methods in the case of Julia) where Python can reach a similar speed as Julia or even cases where Julia is outperformed. People often use one microbenchmark comparison to make claims on the whole package, but this is no reference for real application that we want to use our programming language for. Let's look back at the problem of the Lorenz system. The `scipy` package in Python provides fundamental algorithms, including differential equation solvers. In this example the limitations of the Numba package become evident.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fdcaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import timeit\n",
    "import numba\n",
    " \n",
    "def lorenz(u, t, sigma, rho, beta):\n",
    "    x, y, z = u\n",
    "    return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]\n",
    " \n",
    "u0 = [1.0,0.0,0.0]\n",
    "tspan = (0., 100.)\n",
    "t = np.linspace(0, 100, 1001)\n",
    "sol = odeint(lorenz, u0, t, args=(10.0,28.0,8/3))\n",
    "\n",
    "def time_func():\n",
    "    odeint(lorenz, u0, t, args=(10.0,28.0,8/3),rtol = 1e-8, atol=1e-8)\n",
    " \n",
    "time_func()\n",
    "timeit.Timer(time_func).timeit(number=100)/100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5129fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "numba_f = numba.jit(lorenz,nopython=True)\n",
    "def time_func():\n",
    "    odeint(numba_f, u0, t, args=(10.0,28.0,8/3),rtol = 1e-8, atol=1e-8)\n",
    " \n",
    "time_func()\n",
    "timeit.Timer(time_func).timeit(number=100)/100 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe828db5",
   "metadata": {},
   "source": [
    "Where you can optimize the function `lorenz()` itself, which is called (multiple times) at each timestep, it is not possible to further optimize the code that sits between two of your optimized function calls. This is exactly what can hurt your performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337af602",
   "metadata": {},
   "source": [
    "Now you can allow the function to be Julia code using the very recent `diffeqpy` library which introduces the *DifferentialEquations.jl* package to python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00462be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from julia import Main\n",
    "from diffeqpy import de\n",
    "import numpy as np\n",
    "jul_f = Main.eval(\"\"\"\n",
    "function f(du,u,p,t)\n",
    "  x, y, z = u[1], u[2], u[3]\n",
    "  sigma, rho, beta = p[1], p[2], p[3]\n",
    "  du[1] = sigma * (y - x)\n",
    "  du[2] = x * (rho - z) - y\n",
    "  du[3] = x * y - beta * z\n",
    "end\"\"\")\n",
    "u0 = [1.0,0.0,0.0]\n",
    "tspan = (0., 100.)\n",
    "t = np.linspace(0, 100, 1001)\n",
    "p = [10.0,28.0,8/3]\n",
    "prob = de.ODEProblem(jul_f, u0, tspan, p)\n",
    "sol = de.solve(prob,saveat=t,abstol=1e-8,reltol=1e-8)\n",
    " \n",
    "def time_func():\n",
    "    sol = de.solve(prob,saveat=t,abstol=1e-8,reltol=1e-8)\n",
    " \n",
    "time_func()\n",
    "timeit.Timer(time_func).timeit(number=100)/100 # 0.0033111710000000016 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403d028f",
   "metadata": {},
   "source": [
    "This way you can avoid the Python context switches that were the remaining bottleneck.<br>\n",
    "<br>\n",
    "Again we can compare with the most basic implementation in Julia and see that there is already a gain in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d938a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.211 ms (8127 allocations: 701.91 KiB)\n",
      "  2.795 ms (1053 allocations: 127.42 KiB)\n"
     ]
    }
   ],
   "source": [
    "using DifferentialEquations, BenchmarkTools\n",
    "function lorenz!(du,u,p,t)\n",
    "    du[1] = p[1]*(u[2]-u[1])\n",
    "    du[2] = u[1]*(p[2]-u[3]) - u[2]\n",
    "    du[3] = u[1]*u[2] - p[3]*u[3]\n",
    "end\n",
    "u0 = [1.0;0.0;0.0]\n",
    "p = [10.0,28.0,8/3]\n",
    "tspan = (0.0,100.0)\n",
    "prob = ODEProblem(lorenz!,u0,tspan,p)\n",
    "@btime solve(prob,saveat=0.1,reltol=1e-8,abstol=1e-8); # 2.467 ms (13436 allocations: 1.00 MiB)\n",
    "@btime solve(prob,Tsit5(),saveat=0.1,reltol=1e-8,abstol=1e-8); # 2.904 ms (1081 allocations: 155.70 KiB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1917d4d2",
   "metadata": {},
   "source": [
    "With the most optimized implementation that we wrote the difference becomes even bigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2471095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.078 ms (75 allocations: 89.66 KiB)\n",
      "  1.661 ms (27 allocations: 63.19 KiB)\n"
     ]
    }
   ],
   "source": [
    "using StaticArrays\n",
    "function lorenz_static(u,p,t)\n",
    "    @inbounds begin\n",
    "        dx = p[1]*(u[2]-u[1])\n",
    "        dy = u[1]*(p[2]-u[3]) - u[2]\n",
    "        dz = u[1]*u[2] - p[3]*u[3]\n",
    "    end\n",
    "    @SVector [dx,dy,dz]\n",
    "end\n",
    "u0 = @SVector [1.0,0.0,0.0]\n",
    "p  = @SVector [10.0,28.0,8/3]\n",
    "tspan = (0.0,100.0)\n",
    "prob = ODEProblem(lorenz_static,u0,tspan,p)\n",
    "@btime solve(prob,saveat=0.1,reltol=1e-8,abstol=1e-8);\n",
    "@btime solve(prob,Tsit5(),saveat=0.1,reltol=1e-8,abstol=1e-8);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae869d48",
   "metadata": {},
   "source": [
    "\\[2\\] Chris Rackauckas, *Why Numba and Cython are not substitutes for Julia*, Stochastic Life, http://www.stochasticlifestyle.com/why-numba-and-cython-are-not-substitutes-for-julia/, \\[August 2018\\]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
